<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audio Visualization</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <style>
        body {
            margin: 0;
            height: 100vh;
        }

        .logo-container, .logo, .container, .clone {
            width: 300px;
            height: 300px;
            position: absolute;
            top: 0;
            bottom: 0;
            left: 0;
            right: 0;
            margin: auto;
        }

        .logo-container, .clone {
            background: black;
            border-radius: 200px;
        }

        .mask {
            overflow: hidden;
            will-change: transform;
            position: absolute;
            transform: none;
            top: 0; left: 0;
        }
    </style>
</head>
<body>
    <div class="logo-container">
        <img src="img/logo.svg" alt="" class="logo">
    </div>

    <script>
        // ----------------------------------
        // audio code
        // ----------------------------------

        /* Setup an AudioContext, default to the non-prefixed version if possible. */
        var context
          , audio
          , processor
          , analyser
          , data;

        /* Try instantiating a new AudioContext, throw an error if it fails. */
        try {
            /* Setup an AudioContext. */
            context = new AudioContext();

            /* Create a script processor node with a `bufferSize` of 1024. */
            processor = context.createScriptProcessor(1024);

            /* Create an analyser node */
            analyser = context.createAnalyser();

            /* Wire the processor into our audio context. */
            processor.connect(context.destination);

            /* Wire the analyser into the processor */
            analyser.connect(processor);

            /* Define a Uint8Array to receive the analysers data. */
            data = new Uint8Array(analyser.frequencyBinCount);
        } catch(e) {
            throw new Error('The Web Audio API is unavailable');
        }

        var Sound = {
            element: undefined,
            init: false,

            play: function() {
                if (this.init === false) {
                    var sound = context.createMediaElementSource(this.element);

                    this.element.onended = function() {
                        sound.disconnect();
                        sound = null;

                        /* Noop the audioprocess handler when the file finishes. */
                        processor.onaudioprocess = function() {};
                    }

                    /* Add the following line to wire into the analyser. */
                    sound.connect(analyser);
                    sound.connect(context.destination);

                    processor.onaudioprocess = function() {
                        /* Populate the data array with the frequency data. */
                        analyser.getByteTimeDomainData(data);
                    };

                    this.init = true;
                }

                this.element.play();
            },

            pause: function() {
                this.element.pause();
            },

            paused: function() {
                return this.element.paused;
            }
        };

        function loadAudioElement(url) {
            return new Promise(function(resolve, reject) {
                var audio = new Audio(); // audio DOM element, same as createElement('audio')

                audio.addEventListener('canplay', function() {
                    resolve(audio);
                });

                audio.addEventListener('error', reject);
                audio.src = url;
                audio.controls = true;
            });
        }

        loadAudioElement('/audio/Cutside_-_08_-_Amaterasu.mp3').then(function(elem) {
            audio = Object.create(Sound);
            audio.element = elem;
            audio.play();
        }, function(elem) {
            throw elem.error;
        });

        // ----------------------------------
        // visualization code
        // ----------------------------------

        const NUM_OF_SLICES = 20
            , STEP = Math.floor(data.length / NUM_OF_SLICES)
            , NO_SIGNAL = 128;

        let logo = document.querySelector('.logo-container');
        let logoImg = document.querySelector('.logo');

        var slices = []
          , rect = logo.getBoundingClientRect()
          , width = rect.width
          , height = rect.height
          , widthPerSlice = width / NUM_OF_SLICES;

        /* Create a container `<div>` to hold our 'slices'. */
        var container = document.createElement('div');
        container.className = 'container';
        container.style.width = width + 'px';
        container.style.height = height + 'px';

        var containerFrag = document.createDocumentFragment();

        /* Let's create our 'slices'. */
        for (var i = 0; i < NUM_OF_SLICES; i++) {
            /* Calculate the `offset` for each individual 'slice'. */
            var offset = i * widthPerSlice;

            /* Create a mask `<div>` for this 'slice'. */
            var mask = document.createElement('div');
            mask.className = 'mask';
            mask.style.width = widthPerSlice + 'px';
            /* For the best performance, and to prevent artefacting when we
             * use `scale` we instead use a 2d `matrix` that is in the form:
             * matrix(scaleX, 0, 0, scaleY, translateX, translateY). We initially
             * translate by the `offset` on the x-axis. */
            mask.style.transform = 'matrix(1, 0, 0, 1,' + offset + ', 0)';

            // Clone the original element.
            var clone = logo.cloneNode(true);
            clone.className = 'clone';
            clone.style.width = width + 'px';
            /* We won't be changing this transform so we don't need to use a matrix. */
            clone.style.transform = 'translate3d(' + -offset + 'px, 0, 0)';
            clone.style.height = mask.style.height = height + 'px';

            mask.appendChild(clone);
            containerFrag.appendChild(mask);

            /* We need to maintain the `offset` for when we
             * alter the transform in `requestAnimationFrame`. */
            slices.push({ offset: offset, elem: mask });
        }

        container.appendChild(containerFrag);

        /* Replace the original element with our new container of 'slices'. */
        document.body.replaceChild(container, logo);

        container.addEventListener('click', function(ev) {
            if (audio.paused()) {
                audio.play();
            } else {
                audio.pause();
            }
        })

        /* Create our `render` function to be called every available frame. */
        function render() {
            /* Request a `render` on the next available frame.
             * No need to polyfill because we are in Chrome. */
            requestAnimationFrame(render);

            /* Loop through our 'slices' and use the STEP(n) data from the
             * analysers data. */
            for (var i = 0, n = 0; i < NUM_OF_SLICES; i++, n+=STEP) {
                var slice = slices[i],
                    elem = slice.elem,
                    offset = slice.offset;

                /* Make sure the val is positive and divide it by `NO_SIGNAL`
                 * to get a value suitable for use on the Y scale. */
                var val = Math.abs(data[n]) / NO_SIGNAL;
                /* Change the scaleY value of our 'slice', while keeping it's
                 * original offset on the x-axis. */
                elem.style.transform = 'matrix(1,0,0,' + val + ',' + offset + ', 0)';
                elem.style.opacity = val;
            }
        }

        /* Call the `render` function initially. */
        render();
    </script>
</body>
</html>
